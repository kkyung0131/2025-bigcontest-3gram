prior_sd <- 0.5
# likelihood of Poisson distribution
pois_lik <- function(lambda, x){
return(prod(dpois(x, lambda)))
}
# unnormalized posterior
posterior_unnorm <- function(lambda, x) {
dlnorm(lambda, meanlog = prior_mean, sdlog = prior_sd) * pois_lik(lambda, x)
}
# mle of lambda
lambda_mle <- mean(obs)  # Poisson MLE = sample mean
lambda_mle
# sampling
set.seed(2025)
n_samples <- 10000
lambda_samples <- numeric(n_samples)
accepted <- 0
for (i in 1:n_samples) {
# Sample lambda_i from lognormal prior
lambda_i <- rlnorm(1, meanlog = prior_mean, sdlog = prior_sd)
# Sample uniform u_i
u_i <- runif(1)
# Acceptance ratio = likelihood ratio
accept_prob <- pois_lik(lambda_i, obs) / pois_lik(lambda_mle, obs)
if (u_i < accept_prob) {
lambda_samples[i] <- lambda_i
accepted <- accepted + 1
} else {
lambda_samples[i] <- NA
}
}
# Remove rejected samples
lambda_samples <- lambda_samples[!is.na(lambda_samples)]
# Acceptance rate
accept_rate <- accepted / n_samples
cat("Acceptance rate:", accept_rate, "\n")
# Posterior moments
post_mean <- mean(lambda_samples)
post_var <- var(lambda_samples)
cat("Posterior mean:", post_mean, "\n")
cat("Posterior variance:", post_var, "\n")
# KDE
df <- data.frame(lambda = lambda_samples)
ggplot(df, aes(x = lambda)) +
geom_density(fill = "skyblue", alpha = 0.5) +
geom_vline(xintercept = post_mean, color = "red", linetype = "dashed") +
labs(title = "Posterior Density of Lambda",
x = expression(lambda),
y = "Density") +
theme_minimal()
ggplot(df, aes(x = lambda)) +
geom_density(fill = "skyblue", alpha = 0.5) +
stat_function(fun = function(x) dlnorm(x, meanlog = prior_mean, sdlog = prior_sd),
color = "lightpink", alpha = 0.5, size = 1, linetype = "dashed") +
geom_vline(xintercept = post_mean, color = "red", linetype = "dashed") +
labs(title = "Posterior Density with Prior Overlay",
x = expression(lambda),
y = "Density") +
theme_minimal() +
annotate("text", x = post_mean, y = max(density(lambda_samples)$y)*0.9,
label = "Posterior mean", color = "red", angle = 90, vjust = -0.5)
df_post <- data.frame(lambda = lambda_samples)
x_min <- min(lambda_samples, qlnorm(0.001, meanlog = prior_mean, sdlog = prior_sd))
x_max <- max(lambda_samples, qlnorm(0.999, meanlog = prior_mean, sdlog = prior_sd))
x_vals <- seq(x_min, x_max, length.out = 1000)
prior_density <- dlnorm(x_vals, meanlog = prior_mean, sdlog = prior_sd)
df_prior <- data.frame(x = x_vals, density = prior_density)
post_density <- density(lambda_samples)
df_post_density <- data.frame(x = post_density$x, density = post_density$y)
ggplot() +
geom_area(data = df_post_density, aes(x = x, y = density),
fill = "skyblue", alpha = 0.5) +
geom_area(data = df_prior, aes(x = x, y = density),
fill = "orange", alpha = 0.3) +
geom_vline(xintercept = mean(lambda_samples), color = "red", linetype = "dashed") +
labs(title = "Posterior vs Prior Distribution",
x = expression(lambda),
y = "Density") +
theme_minimal() +
annotate("text", x = mean(lambda_samples), y = max(df_post_density$density)*0.9,
label = "Posterior mean", color = "red", angle = 90, vjust = -0.5)
df_post <- data.frame(lambda = lambda_samples)
x_min <- min(lambda_samples, qlnorm(0.001, meanlog = prior_mean, sdlog = prior_sd))
x_max <- max(lambda_samples, qlnorm(0.999, meanlog = prior_mean, sdlog = prior_sd))
x_vals <- seq(x_min, x_max, length.out = 1000)
prior_density <- dlnorm(x_vals, meanlog = prior_mean, sdlog = prior_sd)
df_prior <- data.frame(x = x_vals, density = prior_density)
post_density <- density(lambda_samples)
df_post_density <- data.frame(x = post_density$x, density = post_density$y)
ggplot() +
geom_area(data = df_post_density, aes(x = x, y = density),
fill = "skyblue", alpha = 0.5) +
geom_area(data = df_prior, aes(x = x, y = density),
fill = "lightpink", alpha = 0.3) +
geom_vline(xintercept = mean(lambda_samples), color = "red", linetype = "dashed") +
labs(title = "Posterior vs Prior Distribution",
x = expression(lambda),
y = "Density") +
theme_minimal() +
annotate("text", x = mean(lambda_samples), y = max(df_post_density$density)*0.9,
label = "Posterior mean", color = "red", angle = 90, vjust = -0.5)
df_post <- data.frame(lambda = lambda_samples)
x_min <- min(lambda_samples, qlnorm(0.001, meanlog = prior_mean, sdlog = prior_sd))
x_max <- max(lambda_samples, qlnorm(0.999, meanlog = prior_mean, sdlog = prior_sd))
x_vals <- seq(x_min, x_max, length.out = 1000)
prior_density <- dlnorm(x_vals, meanlog = prior_mean, sdlog = prior_sd)
df_prior <- data.frame(x = x_vals, density = prior_density)
post_density <- density(lambda_samples)
df_post_density <- data.frame(x = post_density$x, density = post_density$y)
ggplot() +
geom_area(data = df_post_density, aes(x = x, y = density),
fill = "skyblue", alpha = 0.5) +
geom_area(data = df_prior, aes(x = x, y = density),
fill = "lightpink", alpha = 0.5) +
geom_vline(xintercept = mean(lambda_samples), color = "red", linetype = "dashed") +
labs(title = "Posterior vs Prior Distribution",
x = expression(lambda),
y = "Density") +
theme_minimal() +
annotate("text", x = mean(lambda_samples), y = max(df_post_density$density)*0.9,
label = "Posterior mean", color = "red", angle = 90, vjust = -0.5)
ggplot() +
geom_area(data = df_post_density, aes(x = x, y = density),
fill = "skyblue", alpha = 0.5, color = "blue") +
geom_area(data = df_prior, aes(x = x, y = density),
fill = "lightpink", alpha = 0.5, color = "violet") +
geom_vline(xintercept = mean(lambda_samples), color = "red", linetype = "dashed") +
labs(title = "Posterior vs Prior Distribution",
x = expression(lambda),
y = "Density") +
theme_minimal() +
annotate("text", x = mean(lambda_samples), y = max(df_post_density$density)*0.9,
label = "Posterior mean", color = "red", angle = 90, vjust = -0.5)
ggplot() +
geom_area(data = df_post_density, aes(x = x, y = density),
fill = "skyblue", alpha = 0.5, color = "blue") +
geom_area(data = df_prior, aes(x = x, y = density),
fill = "lightpink", alpha = 0.5, color = "violet") +
geom_vline(xintercept = mean(lambda_samples), color = "red", linetype = "dashed") +
labs(title = "Posterior vs Prior Distribution",
x = expression(lambda),
y = "Density") +
theme_minimal() +
annotate("text", x = mean(lambda_samples), y = max(df_post_density$density)*0.9,
label = "Posterior mean", color = "red", angle = 0, vjust = -0.5)
write.csv(bb %>% filter(id == "3F14DF48F3"),
"./2025 빅콘테스트/persona_b.csv",
row.names = FALSE)
library(tidyverse)
write.csv(bb %>% filter(id == "3F14DF48F3"),
"./2025 빅콘테스트/persona_b.csv",
row.names = FALSE)
bb <- read.csv("./2025 빅콘테스트/test_for_cust_pattern_4class.csv")
View(bb)
library(tidyverse)
write.csv(bb %>% filter(id == "3F14DF48F3"),
"./2025 빅콘테스트/persona_b.csv",
row.names = FALSE)
shiny::runApp('C:/R shiny/store-risk-score-dashboard')
runApp('C:/R shiny/store-risk-score-dashboard')
source("final_sales_model_pipeline.R")
train_df <- read.csv("./train_for_sales_risk_score.csv")
test_df <- read.csv("./test_for_sales_risk_score.csv")
rf_model <- rand_forest(
mtry = 20,
trees = 500,
min_n = 5
) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("regression")
# ------------------------------------------------------------------------------
# 2. 데이터 분할
# ------------------------------------------------------------------------------
set.seed(2025)
split <- initial_split(train_df, prop = 0.8)
training <- training(split)
valid <- testing(split)
quarters <- sort(unique(train_df$ym_quarter))
# ------------------------------------------------------------------------------
# 3. 분기별 모델 학습 함수
# ------------------------------------------------------------------------------
fit_quarter_model <- function(q) {
# 분기별 데이터 필터링
training_q <- training %>% filter(ym_quarter == q)
rf_rec <- recipe(sales_risk_score ~ ., data = training_q) %>%
update_role(
id, ym_quarter, big_ind, dong, sales_amt_cat_mean, sales_amt_cat_std,
sales_cnt_cat_mean, sales_cnt_cat_std, aov_cat_mean, aov_cat_std,
ind_sales_amt_rat_mean, ind_sales_amt_rat_std, ind_sales_cnt_rat_mean,
ind_sales_cnt_rat_std,
new_role = "ID"
) %>%
step_dummy(all_nominal_predictors())  # 범주형 변수 더미화
# 워크플로우 구성 및 학습
rf_wflow <- workflow() %>%
add_model(rf_model) %>%
add_recipe(rf_rec)
fit <- fit(rf_wflow, training_q)
# 변수 중요도 추출
imp <- fit %>%
extract_fit_engine() %>%
ranger::importance() %>%
sort(decreasing = TRUE) %>%
tibble::enframe(name = "feature", value = "importance") %>%
mutate(quarter = q)
list(quarter = q, model = fit, importance = imp)
}
# ------------------------------------------------------------------------------
# 4. 분기별 모델 학습
# ------------------------------------------------------------------------------
models <- map(quarters, fit_quarter_model)
# ------------------------------------------------------------------------------
# 5. 앙상블 예측 (검증 데이터)
# ------------------------------------------------------------------------------
preds_valid_all <- map(models, ~ predict(.x$model, valid, type = "numeric")) %>%
reduce(bind_cols)
names(preds_valid_all) <- paste0("pred_", seq_along(models))
preds_valid_ensemble <- preds_valid_all %>%
rowwise() %>%
mutate(sales_risk_pred = mean(c_across(starts_with("pred_")), na.rm = TRUE)) %>%
ungroup() %>%
bind_cols(valid %>% select(sales_risk_score, ym_quarter))
# ------------------------------------------------------------------------------
# 6. 검증 데이터 성능 지표
# ------------------------------------------------------------------------------
metrics_valid <- metric_set(rmse, rsq, mae)(
preds_valid_ensemble,
truth = sales_risk_score,
estimate = sales_risk_pred
)
print(metrics_valid)
# ------------------------------------------------------------------------------
# 7. 테스트 데이터 예측
# ------------------------------------------------------------------------------
preds_test_all <- map(models, ~ predict(.x$model, test_df, type = "numeric")) %>%
reduce(bind_cols)
names(preds_test_all) <- paste0("pred_", seq_along(models))
preds_test_ensemble <- preds_test_all %>%
rowwise() %>%
mutate(sales_risk_pred = mean(c_across(starts_with("pred_")), na.rm = TRUE)) %>%
ungroup() %>%
bind_cols(test_df %>% select(sales_risk_score, ym_quarter))
# ------------------------------------------------------------------------------
# 8. 테스트 데이터 성능 지표
# ------------------------------------------------------------------------------
metrics_test <- metric_set(rmse, rsq, mae)(
preds_test_ensemble,
truth = sales_risk_score,
estimate = sales_risk_pred
)
print(metrics_test)
# ------------------------------------------------------------------------------
# 9. 실제 vs 예측 시각화
# ------------------------------------------------------------------------------
ggplot(preds_test_ensemble, aes(x = sales_risk_score, y = sales_risk_pred)) +
geom_point(alpha = 0.5) +
geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Ensemble Regression: Actual vs Predicted",
x = "Actual sales_risk_score",
y = "Predicted sales_risk_score"
) +
theme_minimal()
# ------------------------------------------------------------------------------
# 10. 변수 중요도(Feature Importance) 확인
# ------------------------------------------------------------------------------
# 분기별 중요도 데이터 결합
importance_all <- map_dfr(models, "importance")
# 평균 중요도 계산
importance_mean <- importance_all %>%
group_by(feature) %>%
summarise(mean_importance = mean(importance, na.rm = TRUE)) %>%
arrange(desc(mean_importance))
# 상위 20개 변수 시각화
ggplot(importance_mean %>% slice_max(mean_importance, n = 20),
aes(x = reorder(feature, mean_importance), y = mean_importance)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(
title = "Average Feature Importance (across all quarters)",
x = "Feature",
y = "Mean Importance"
) +
theme_minimal()
shiny::runApp('C:/R shiny/store-risk-score-dashboard')
runApp('C:/R shiny/store-risk-score-dashboard')
7777777
55555
5
51
options(scipen = 999)
source("final_newdata_pipeline.R")
is_closed <- read.csv("./bigcon_for_weighted.csv")
dim(is_closed)
#View(is_closed)
test <- read.csv("./bigcon_test_id.csv")
set.seed(7777777)
random_ids <- sample(unique(test$id), 127)
test <- test %>% filter(id %in% random_ids)
dim(test)
sales_models <- load_models("./my_sales_models_2.rds")
# is_closed == 1
sales_closed <- process_pipeline_sales_newdata(is_closed)
sales_pred_closed <- predict_score_sales(sales_models, sales_closed)
head(sales_pred_closed)
sales_score_closed <- sales_pred_closed$sales_risk_pred
ggplot(as.data.frame(sales_score_closed), aes(x = sales_score_closed)) +
geom_density(fill = "skyblue", alpha = 0.5, color = "blue") + xlim(0,1) + ylim(0, 3)
# is_closed == 0
sales_test <- process_pipeline_sales_newdata(test)
sales_pred_test<- predict_score_sales(sales_models, sales_test)
head(sales_pred_test)
sales_score_test <- sales_pred_test$sales_risk_pred
ggplot(as.data.frame(sales_score_test), aes(x = sales_score_test)) +
geom_density(fill = "lightpink", alpha = 0.5, color = "violet") + xlim(0,1) + ylim(0, 3)
# 비교
sales_scores <- data.frame(
score = c(sales_score_closed, sales_score_test),
group = c(rep("폐업 업체", length(sales_score_closed)),
rep("정상 업체", length(sales_score_test)))
)
ggplot(sales_scores, aes(x = score, fill = group, color = group)) +
geom_density(alpha = 0.4) +
scale_fill_manual(values = c("폐업 업체" = "skyblue", "정상 업체" = "lightpink")) +
scale_color_manual(values = c("폐업 업체" = "blue", "정상 업체" = "violet")) +
xlim(0, 1) + ylim(0, 3)
# 정규성 검정 - 정규성 없음
shapiro.test(sales_score_closed)
shapiro.test(sales_score_test)
# t-test - 차이 없음
wilcox.test(sales_score_closed, sales_score_test, alternative = "greater")
options(scipen = 999)
source("final_newdata_pipeline.R")
is_closed <- read.csv("./bigcon_for_weighted.csv")
dim(is_closed)
#View(is_closed)
test <- read.csv("./bigcon_test_id.csv")
set.seed(55555)
random_ids <- sample(unique(test$id), 127)
test <- test %>% filter(id %in% random_ids)
dim(test)
sales_models <- load_models("./my_sales_models_2.rds")
# is_closed == 1
sales_closed <- process_pipeline_sales_newdata(is_closed)
sales_pred_closed <- predict_score_sales(sales_models, sales_closed)
head(sales_pred_closed)
sales_score_closed <- sales_pred_closed$sales_risk_pred
ggplot(as.data.frame(sales_score_closed), aes(x = sales_score_closed)) +
geom_density(fill = "skyblue", alpha = 0.5, color = "blue") + xlim(0,1) + ylim(0, 3)
# is_closed == 0
sales_test <- process_pipeline_sales_newdata(test)
sales_pred_test<- predict_score_sales(sales_models, sales_test)
head(sales_pred_test)
sales_score_test <- sales_pred_test$sales_risk_pred
ggplot(as.data.frame(sales_score_test), aes(x = sales_score_test)) +
geom_density(fill = "lightpink", alpha = 0.5, color = "violet") + xlim(0,1) + ylim(0, 3)
# 비교
sales_scores <- data.frame(
score = c(sales_score_closed, sales_score_test),
group = c(rep("폐업 업체", length(sales_score_closed)),
rep("정상 업체", length(sales_score_test)))
)
ggplot(sales_scores, aes(x = score, fill = group, color = group)) +
geom_density(alpha = 0.4) +
scale_fill_manual(values = c("폐업 업체" = "skyblue", "정상 업체" = "lightpink")) +
scale_color_manual(values = c("폐업 업체" = "blue", "정상 업체" = "violet")) +
xlim(0, 1) + ylim(0, 3)
# 정규성 검정 - 정규성 없음
shapiro.test(sales_score_closed)
shapiro.test(sales_score_test)
# t-test - 차이 없음
wilcox.test(sales_score_closed, sales_score_test, alternative = "greater")
options(scipen = 999)
source("final_newdata_pipeline.R")
is_closed <- read.csv("./bigcon_for_weighted.csv")
dim(is_closed)
#View(is_closed)
test <- read.csv("./bigcon_test_id.csv")
set.seed(51)
random_ids <- sample(unique(test$id), 127)
test <- test %>% filter(id %in% random_ids)
dim(test)
sales_models <- load_models("./my_sales_models_2.rds")
# is_closed == 1
sales_closed <- process_pipeline_sales_newdata(is_closed)
sales_pred_closed <- predict_score_sales(sales_models, sales_closed)
head(sales_pred_closed)
sales_score_closed <- sales_pred_closed$sales_risk_pred
ggplot(as.data.frame(sales_score_closed), aes(x = sales_score_closed)) +
geom_density(fill = "skyblue", alpha = 0.5, color = "blue") + xlim(0,1) + ylim(0, 3)
# is_closed == 0
sales_test <- process_pipeline_sales_newdata(test)
sales_pred_test<- predict_score_sales(sales_models, sales_test)
head(sales_pred_test)
sales_score_test <- sales_pred_test$sales_risk_pred
ggplot(as.data.frame(sales_score_test), aes(x = sales_score_test)) +
geom_density(fill = "lightpink", alpha = 0.5, color = "violet") + xlim(0,1) + ylim(0, 3)
# 비교
sales_scores <- data.frame(
score = c(sales_score_closed, sales_score_test),
group = c(rep("폐업 업체", length(sales_score_closed)),
rep("정상 업체", length(sales_score_test)))
)
ggplot(sales_scores, aes(x = score, fill = group, color = group)) +
geom_density(alpha = 0.4) +
scale_fill_manual(values = c("폐업 업체" = "skyblue", "정상 업체" = "lightpink")) +
scale_color_manual(values = c("폐업 업체" = "blue", "정상 업체" = "violet")) +
xlim(0, 1) + ylim(0, 3)
# 정규성 검정 - 정규성 없음
shapiro.test(sales_score_closed)
shapiro.test(sales_score_test)
# t-test - 차이 없음
wilcox.test(sales_score_closed, sales_score_test, alternative = "greater")
options(scipen = 999)
source("final_newdata_pipeline.R")
is_closed <- read.csv("./bigcon_for_weighted.csv")
dim(is_closed)
#View(is_closed)
test <- read.csv("./bigcon_test_id.csv")
set.seed(2025)
random_ids <- sample(unique(test$id), 127)
test <- test %>% filter(id %in% random_ids)
dim(test)
sales_models <- load_models("./my_sales_models_2.rds")
# is_closed == 1
sales_closed <- process_pipeline_sales_newdata(is_closed)
sales_pred_closed <- predict_score_sales(sales_models, sales_closed)
head(sales_pred_closed)
sales_score_closed <- sales_pred_closed$sales_risk_pred
ggplot(as.data.frame(sales_score_closed), aes(x = sales_score_closed)) +
geom_density(fill = "skyblue", alpha = 0.5, color = "blue") + xlim(0,1) + ylim(0, 3)
# is_closed == 0
sales_test <- process_pipeline_sales_newdata(test)
sales_pred_test<- predict_score_sales(sales_models, sales_test)
head(sales_pred_test)
sales_score_test <- sales_pred_test$sales_risk_pred
ggplot(as.data.frame(sales_score_test), aes(x = sales_score_test)) +
geom_density(fill = "lightpink", alpha = 0.5, color = "violet") + xlim(0,1) + ylim(0, 3)
# 비교
sales_scores <- data.frame(
score = c(sales_score_closed, sales_score_test),
group = c(rep("폐업 업체", length(sales_score_closed)),
rep("정상 업체", length(sales_score_test)))
)
ggplot(sales_scores, aes(x = score, fill = group, color = group)) +
geom_density(alpha = 0.4) +
scale_fill_manual(values = c("폐업 업체" = "skyblue", "정상 업체" = "lightpink")) +
scale_color_manual(values = c("폐업 업체" = "blue", "정상 업체" = "violet")) +
xlim(0, 1) + ylim(0, 3)
# 정규성 검정 - 정규성 없음
shapiro.test(sales_score_closed)
shapiro.test(sales_score_test)
# t-test - 차이 없음
wilcox.test(sales_score_closed, sales_score_test, alternative = "greater")
shiny::runApp('C:/R shiny/store-risk-score-dashboard')
runApp('C:/R shiny/store-risk-score-dashboard')
runApp('C:/R shiny/store-risk-score-dashboard')
source("./scripts/01_load_packages.R")
source("./scripts/02_basic_preprocessing.R")
source("./scripts/03_data_pipeline_models.R")
source("./scripts/04_train_models.R")
source("./scripts/05_predict.R")
setwd(C:/Users/lgpc/GitHub/2025-bigcontest-3gram)
setwd("C:/Users/lgpc/GitHub/2025-bigcontest-3gram")
# data load
data1 <- read.csv("./data/raw/big_data_set1_f.csv")
source("./scripts/01_load_packages.R")
source("./scripts/02_basic_preprocessing.R")
source("./scripts/03_data_pipeline_models.R")
source("./scripts/04_train_models.R")
source("./scripts/05_predict.R")
dim(read.csv(".data/processed/bigcon_open_train.csv"))
dim(read.csv("./data/processed/bigcon_open_train.csv"))
install.packages("googledrive")
# 3-4. Load pre-trained RDS models
drive_find(pattern = "my_sales_models_2.rds")
library(googledrive)
# 3-4. Load pre-trained RDS models
drive_find(pattern = "my_sales_models_2.rds")
sales_models     <- readRDS("./models/my_sales_models_2.rds")
sales_cat_models <- readRDS("./models/sales_model_xgb_regression.rds")
cust_models      <- readRDS("./models/my_cust_models_4class.rds")
mkt_model        <- readRDS("./models/my_mkt_models_2.rds")
sales_models     <- readRDS("./models/my_sales_models_2.rds")
sales_cat_models <- readRDS("./models/sales_model_xgb_regression.rds")
cust_models      <- readRDS("./models/my_cust_models_4class.rds")
mkt_model        <- readRDS("./models/my_mkt_models_2.rds")
# -----------------------------
# Options
# -----------------------------
run_pipeline <- FALSE   # TRUE: Run full preprocessing pipeline from raw data
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
rlang::last_trace()
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
rlang::last_trace()
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
head(final_score_closed)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
final_score_closed
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
source("C:/Users/lgpc/GitHub/2025-bigcontest-3gram/06_final_model.R", echo=TRUE)
shiny::runApp('C:/R shiny/store-risk-score-dashboard')
runApp('app')
runApp('app')
runApp('app')
